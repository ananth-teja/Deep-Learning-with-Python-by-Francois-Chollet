{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Keras Funtional API\n",
    "\n",
    "------\n",
    "\n",
    "Keras functional API helps create Graph like models just like python functions. Keras callbacks and tensorboard allows us to monitor the performance of the model and use functions like Earlystopping whenever necessary. \n",
    "\n",
    "The chapter also discusses the important research in deep learning like batch normalization layers, residual networks, hyperparamter adjustments, and ensemble modelling.\n",
    "\n",
    "\n",
    "Until now all the models which have been discussed have been Sequential. The sequential models are simple single input, single output models. Here we will discuss special models which might have multiple inputs or multiple outputs. Some might have data coming from different sources and it might need to merge the data.(Multimodal inputs). \n",
    "\n",
    "Example, consider a scenario where we have to predict cost of an item given some text, meta data, and an image. Training three different models does not make sense. So here what can be done is that The three models can be merged using a merging module and even this merging module would get trained. \n",
    "\n",
    "Also, there are a lot of architectures like Google Inception architecture which requires several parallel branches whose outputs are merged into a single tensor. \n",
    "\n",
    "Also, there is a ResNet architecture which involves reinjecting of previous information in downstream flow by adding the past output tensor to later output tensor. These architectures will be discussed in great depth later. Skip if you don't understand the connection now. \n",
    "\n",
    "---------------------------\n",
    "\n",
    "With functional API the layers can be esentially be trated as functions. Each layer taking a tensor and returning a tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "***Introduction to Functional API***\n",
    "\n",
    "\n",
    "---------\n",
    "\n",
    "For the sake of simplicaity let's start with a sequential model using functional API. This would help us understand the syntax better. Here we are building a dense model using Keras Sequential API. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation = 'relu', input_shape = (64,)))\n",
    "seq_model.add(layers.Dense(32, activation = 'relu'))\n",
    "seq_model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466.0\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Writing it's functional equivalent***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = layers.Input(shape=(64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466.0\n",
      "Trainable params: 3,466.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Basically Model is a Graph like data structure which is created by Keras using just the input and output tensor. As the output_tensor is esentially created by repeatedly transforming the input_tensor.***\n",
    "\n",
    "If we try to create a Model object using disconnected graph Keras will throw a run time error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "***Multi-input Models - Question-Answer System*** \n",
    "\n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "Multi input models require the converging of data which can be done by using different transformations. The merge operations can usually be performed by using the *keras.layers.add* or *keras.layers.concatenate*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The text_input is a variable size integer array. The layers can be named using the name field. \n",
    "text_input = layers.Input(shape = (None,), dtype = 'int32', name = 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embeds the input into sequence of vectors of size 64.\n",
    "\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yash/anaconda3/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1044: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "### Encodes the vectorsin a single vector using LSTM \n",
    "\n",
    "encoded_data = layers.LSTM(32)(embedded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Same process for question part***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The text_input is a variable size integer array. The layers can be named using the name field. \n",
    "question_input = layers.Input(shape = (None,), dtype = 'int32', name = 'question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embeds the input into sequence of vectors of size 64.\n",
    "\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encodes the vectorsin a single vector using LSTM \n",
    "\n",
    "encoded_question = layers.LSTM(32)(embedded_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Merging the encoded question and text data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = layers.concatenate([encoded_data, encoded_question], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = layers.Dense(answer_vocabulary_size, activation = 'softmax')(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([text_input, question_input], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "text (InputLayer)                (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "question (InputLayer)            (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, None, 10000)   640000                                       \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, None, 10000)   320000                                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            1284224                                      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 32)            1284224                                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 500)           32500                                        \n",
      "====================================================================================================\n",
      "Total params: 3,560,948.0\n",
      "Trainable params: 3,560,948.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yash/anaconda3/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feeding data to multi-input model***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.random.randint(1, text_vocabulary_size, size = (num_samples, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = np.random.randint(1, question_vocabulary_size, size = (num_samples, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One hot encoded answers\n",
    "\n",
    "answers = np.random.randint(0, 1, size = (num_samples, answer_vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 5s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24585538d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([text, question], answers, epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s - loss: 0.0000e+00 - acc: 0.5850     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24309a4240>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The values could also be passed as an dict. \n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers, epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "***Multi-output models***\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "A simple example would be a model which tries to predict different properties using the same data. For example consider finding the age, gender, and income from a person's tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_income_groups = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_input = layers.Input(shape = (None,), dtype = 'int32', name = 'posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv1D(256, 5, activation = 'relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation = 'relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation = 'relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_prediction = layers.Dense(1, name = 'age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, \n",
    "                                activation = 'softmax', \n",
    "                                name = 'income')(x)\n",
    "gender_prediction = layers.Dense(1, activation = 'sigmoid', name = 'gender')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "posts (InputLayer)               (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, None, 10000)   2560000                                      \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)               (None, None, 256)     12800256                                     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)   (None, None, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)               (None, None, 256)     327936                                       \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)   (None, None, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)               (None, None, 256)     327936                                       \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalMa (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "age (Dense)                      (None, 1)             129                                          \n",
      "____________________________________________________________________________________________________\n",
      "income (Dense)                   (None, 10)            1290                                         \n",
      "____________________________________________________________________________________________________\n",
      "gender (Dense)                   (None, 1)             129                                          \n",
      "====================================================================================================\n",
      "Total params: 16,050,572.0\n",
      "Trainable params: 16,050,572.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Different loss functions are necessary if we use different output layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = ['mse','categorical_crossentropy', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can also be compiled as follows by using a dict(make sure you add a name tag to all output layers if using dict):\n",
    "\n",
    "```python \n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = { 'age' : 'mse',\n",
    "                      'income' : 'categorical_crossentropy',\n",
    "                      'gender' : 'binary_crossentropy' })\n",
    "```\n",
    "\n",
    "Now, since all the three outputs focus on different things, it might be that the loss contributions will cause the model representations to be optimized preferentially with largest individual loss, at the expense of other tasks. So to avoid this loss weighting can be done. \n",
    "\n",
    "As usually the MSE loss is a little higher than the binary_crossentropy appropriate weighting is necessarry. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = { 'age' : 'mse',\n",
    "                      'income' : 'categorical_crossentropy',\n",
    "                      'gender' : 'binary_crossentropy' },\n",
    "             loss_weights = [0.025, 1. , 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some random data to test dimensionality \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 200\n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size, size = (num_samples, max_length))\n",
    "age_targets = np.random.random(size = (num_samples, ))\n",
    "\n",
    "income_targets = np.random.randint(0, 9, size = (num_samples, ))\n",
    "income_targets = to_categorical(income_targets, num_classes = 10)\n",
    "\n",
    "gender_targets = np.random.randint(0, 1, size = (num_samples, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.5134     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.5071     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.5008     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4945     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4884     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4822     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4762     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4702     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4642     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s - loss: nan - age_loss: nan - income_loss: 1.1921e-07 - gender_loss: 0.4584     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30779bd358>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The data can be fed in following way\n",
    "\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "***Directed Acyclic Graphs of layers****\n",
    "\n",
    "-----\n",
    "\n",
    "With Keras functional API we can also build Directed Acyclic graphs. Several architectures use apecial architectures involving complex structures which require the use of functional API. Two of the important such modules are residual connections and inception module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "Inception Module\n",
    "\n",
    "-------\n",
    "\n",
    "It is a popular architecture inspired by network-in-network architecture. It consists of stack of modules that themselves look like small independent networks. The most basic inception module has 3-4 branches, starting with a 1x1 convolution, followed by a 3x3 convolution, and ending with concatenation of the resulting features. \n",
    "\n",
    "The setup helps the network seperately learn spatial features and channel wise features. which is more efficient than learning them jointly. Complex modules involving Pooling anddifferent spatial convolutions have been also used in some inception modules. \n",
    "\n",
    "---------\n",
    "\n",
    "***Purpose of 1x1 Convolution***\n",
    "\n",
    "-------\n",
    "\n",
    "So the purpose of using bigger kernals was to make sure we get the spatial information encoded within the Weights after training. The 1x1 kernal does not care about the spatial features but focuses on the correlation between the multiple channels. Suppose there are 64 channels in the input and we use a single 1x1 kernal. Then esentially what we are doing is taking a slice from the image across all channels and then passing it through a single neuron and then applying activation function. In this way we are trying to learn the relation between different channels. This helps improve the model a lot as there is a high correlation between multiple channels.\n",
    "\n",
    "This is also used to decrease the number of parameters and increase the training speed of the model. As 1x1 convolution is good way of dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Inception model can be implemented in following way*** \n",
    "\n",
    "##3 Consider there is a input tensor of dimension 4. \n",
    "```python\n",
    "from keras import layers\n",
    "\n",
    "branch_a = layers.Conv2D(128,1,activation = 'relu', strides = 2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128,1,activation = 'relu')(x)\n",
    "branch_b = layers.Conv2D(128,3,activation = 'relu', strides = 2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides = 2)(x)\n",
    "branch_c = layers.Conv2D(128,3,activation = 'relu', strides = 2)(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128,1,activation = 'relu')(x)\n",
    "branch_d = layers.Conv2D(128,3,activation = 'relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128,3,activation = 'relu', stride = 2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis =1)\n",
    "```\n",
    "\n",
    "-------\n",
    "\n",
    "***Xception***\n",
    "\n",
    "-----\n",
    "\n",
    "Xception is an extreme version of Inception model. It takes the logical idea of seperating the spatial and channel wise features to an extreme, and replaces the Inception modules with depth wise sepearable convolutions consisting of depthwise convolutions(spatial convolution where every channel is handled seperately) followed by 1x1 convolution. The model has approximately same number of parameters as original Inception model but performs better than Inception on ImageNet Data as it uses the paramaters more efficiently. \n",
    "\n",
    "-------------\n",
    "\n",
    "***Residual Connections***\n",
    "\n",
    "----\n",
    "\n",
    "It is one of the breakthrough papers in Computer Vision as it tackles two common problems that plague any large scale deep learning model i.e. vanishing gradients, and representational bottlenecks. In general it is beneficial to add residual connections to network of the size 10 layers or more. \n",
    "\n",
    "A residual connection consists of making the output of earlier layer available as input to later layer, effectively creating a short cut in a sequential network. **Rather than being concatenated to the later activation, the earlier output is summed with later activation, which assumes that both activations are the same size.** If they are of different shapes a resize operation can be done using 1x1 convolution without activation or Dense layer. Following is a basic block which shows how Residual connections can be implemented. \n",
    "\n",
    "```python \n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(x)\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(y)\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(y)\n",
    "\n",
    "y = layers.add([y,x], axis = 1)\n",
    "```\n",
    "\n",
    "Following is the snipplet where there is a dimensionality difference. \n",
    "\n",
    "\n",
    "```python \n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(x)\n",
    "y = layers.Conv2D(128, 3, activation = 'relu', padding = 'same')(y)\n",
    "y = layers.MaxPooling2D(2, strides = 2)(y)\n",
    "\n",
    "### Adding this to make the dimensions of the x and y same. \n",
    "residual = layers.Conv2D(128, 1, strides = 2, padding = 'same')(x)\n",
    "\n",
    "y = layers.add([y,residual], axis = 1)\n",
    "```\n",
    "\n",
    "***Representational Bottlenecks*** - In a sequential model, each successive representation layer is built on top of the previous one, which means that it only has access to information contained in the activations of previous layer. **If one layer is too small, then model is constrained by hoe much information can be crammed into activations of this layer.** So residual connections pass the earlier information to later layers even if there exists a representational bottleneck. \n",
    "\n",
    "***Vanishing Gradients*** - Backpropogation the backbone of model training, works by propogating a feedback signal from the output loss down to earlier layers. If the feedback signal has to be propogated through a deep stack of layers, the signal may become tenuous or even be lost entirely,  rendering the network untrainable. The residual connectins act as parallel short track for the gradients to propogate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "***Layer Weight Sharing***\n",
    "\n",
    "-----\n",
    "\n",
    "One of the important features of Funstional API is ability to reuse the layer instance several times. When we call a layer twice without instantiating a new object we are esentially working on the same layer and same weeights of the layer. This means that the this layer can be shared by different branches. \n",
    "\n",
    "Example Application - SUppose we want to find the similarity index between two sentences. The inputs are two sentences and output is the correlation between them. Since, semantic similarity is a symmetric similarity i.e. the output whether the input is A, B or B, A won't matter. So instead of processing the two input layers using seperate instance of LSTM network. same LSTM layer can be shared to learn the representations. This is what is called a **Siamese LSTM Model** or **shared LSTM**. \n",
    "\n",
    "Python pseudo code: \n",
    "\n",
    "```python\n",
    "from keras import layers\n",
    "from keras.models import Models\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "left_input = layers.Input(shape = (None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = layers.Input(shape = (None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis = 1)\n",
    "predictions = layers.Dense(1, activation = 'sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "***Models as layers***\n",
    "\n",
    "-------\n",
    "\n",
    "Models can also be treated as layers. Call a model on a tensor and obtain output tensor can be passed to another layer or model. All the things discussed for layers directly translate to Models. The weights can be reused, Models can take in multiple inputs, outputs etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
