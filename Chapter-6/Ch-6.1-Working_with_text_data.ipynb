{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text and Sequences\n",
    "\n",
    "\n",
    "The fundamental deep learning algorithms for sequence processing are Recurrent Neural Networks and 1D CNN's. Some applications of these algorithms include - \n",
    "\n",
    "1. Document classification and timeseries classification, such as identifying the topic of an article or the author of the book. \n",
    "2. Timeseries comparisons such as estimating how closely related are documents or two stock tickers are - \n",
    "3. Sequence to sequence learning, such as decoding an English sentence into French.\n",
    "4. Sentiment analysis, such as classifying the sentiment of the tweet or movie reviews as positive or negative. \n",
    "5. Timeseries forecasting, such as predicting the future weather at a certain location, given the recent weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing text is the process of transforming text into numeric tensors. This can be done in multiple ways - \n",
    "1. Segment text into words, and transform each word into a vector.\n",
    "2. Segment text into characters, and transform each character into a vector.\n",
    "3. Extract n-grams of words or characters, and transform each n-gram into a vector. N-grams are overlapping groups of multiple consecutive words or characters. \n",
    "\n",
    "-----------\n",
    "\n",
    "Each individual unit is known as ***token*** and the process is known as ***tokenization***. After tokenzation, the text data vectorization is performed before feeding it to the Deep Neural Networks. \n",
    "\n",
    "-----------\n",
    "\n",
    "There are various ways to associate a vector with a token. Two major methods are- \n",
    "1. One hot encoding. \n",
    "2. Token embedding (typically used for words, called as word embedding)\n",
    "\n",
    "-----------\n",
    "\n",
    "***Bag of words*** - It is a model where the order is not preserved and the tokens created are treated as sets rather than a sequence. It is one of the naive approaches in language modelling. \n",
    "\n",
    "------------\n",
    "\n",
    "***One Hot Encoding*** - \n",
    "\n",
    "It is a one of the most common, basic ways to turn a token into a vector. Here a unique integer is associated with each word and then each sentence is vectorized in terms of the presence and absence of a particular word. This was performed in chapter 3 when we were dealing with the IMDB dataset. A dictionary is maintained to save the word-integer mapping and then based on the total number of unique words contained in the dataset the sentences are vectorized. This can also be done at a character level.\n",
    "\n",
    "Let's go over how one hot encoding works - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "token_index = {}\n",
    "\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'on': 4,\n",
       " 'the': 5,\n",
       " 'mat.': 6,\n",
       " 'dog': 7,\n",
       " 'ate': 8,\n",
       " 'my': 9,\n",
       " 'homework.': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10  ## only considering first 10 words of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(shape=(len(samples),\n",
    "                          max_length, \n",
    "                          max(token_index.values())+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "***Character Level Encoding\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "characters = string.printable ## All printable ASCII characters\n",
    "\n",
    "token_index = dict(zip(range(1,len(characters)+1), characters))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.keys())+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '0',\n",
       " 2: '1',\n",
       " 3: '2',\n",
       " 4: '3',\n",
       " 5: '4',\n",
       " 6: '5',\n",
       " 7: '6',\n",
       " 8: '7',\n",
       " 9: '8',\n",
       " 10: '9',\n",
       " 11: 'a',\n",
       " 12: 'b',\n",
       " 13: 'c',\n",
       " 14: 'd',\n",
       " 15: 'e',\n",
       " 16: 'f',\n",
       " 17: 'g',\n",
       " 18: 'h',\n",
       " 19: 'i',\n",
       " 20: 'j',\n",
       " 21: 'k',\n",
       " 22: 'l',\n",
       " 23: 'm',\n",
       " 24: 'n',\n",
       " 25: 'o',\n",
       " 26: 'p',\n",
       " 27: 'q',\n",
       " 28: 'r',\n",
       " 29: 's',\n",
       " 30: 't',\n",
       " 31: 'u',\n",
       " 32: 'v',\n",
       " 33: 'w',\n",
       " 34: 'x',\n",
       " 35: 'y',\n",
       " 36: 'z',\n",
       " 37: 'A',\n",
       " 38: 'B',\n",
       " 39: 'C',\n",
       " 40: 'D',\n",
       " 41: 'E',\n",
       " 42: 'F',\n",
       " 43: 'G',\n",
       " 44: 'H',\n",
       " 45: 'I',\n",
       " 46: 'J',\n",
       " 47: 'K',\n",
       " 48: 'L',\n",
       " 49: 'M',\n",
       " 50: 'N',\n",
       " 51: 'O',\n",
       " 52: 'P',\n",
       " 53: 'Q',\n",
       " 54: 'R',\n",
       " 55: 'S',\n",
       " 56: 'T',\n",
       " 57: 'U',\n",
       " 58: 'V',\n",
       " 59: 'W',\n",
       " 60: 'X',\n",
       " 61: 'Y',\n",
       " 62: 'Z',\n",
       " 63: '!',\n",
       " 64: '\"',\n",
       " 65: '#',\n",
       " 66: '$',\n",
       " 67: '%',\n",
       " 68: '&',\n",
       " 69: \"'\",\n",
       " 70: '(',\n",
       " 71: ')',\n",
       " 72: '*',\n",
       " 73: '+',\n",
       " 74: ',',\n",
       " 75: '-',\n",
       " 76: '.',\n",
       " 77: '/',\n",
       " 78: ':',\n",
       " 79: ';',\n",
       " 80: '<',\n",
       " 81: '=',\n",
       " 82: '>',\n",
       " 83: '?',\n",
       " 84: '@',\n",
       " 85: '[',\n",
       " 86: '\\\\',\n",
       " 87: ']',\n",
       " 88: '^',\n",
       " 89: '_',\n",
       " 90: '`',\n",
       " 91: '{',\n",
       " 92: '|',\n",
       " 93: '}',\n",
       " 94: '~',\n",
       " 95: ' ',\n",
       " 96: '\\t',\n",
       " 97: '\\n',\n",
       " 98: '\\r',\n",
       " 99: '\\x0b',\n",
       " 100: '\\x0c'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "This can be done very easily using Keras by using the preprocessing library\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "sample = ['The cat sat on the mat.','The dog ate my homework.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 1000)\n",
    "\n",
    "### Building words index\n",
    "\n",
    "tokenizer.fit_on_texts(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Turns strings into list of integer indices\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "### One hot encoding\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Number of unique words\n",
    "\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A varient of one hot encoding is one-hot hashing trick***, which can be used when the number of tokens are very large. So here the words can be hashed into vectors of fixed size. This is typically done with very lightweight hash function. **Positives:** No need to keep in memory index. **Negatives:** Hash collisions can corrupt data. Can be handled by using larger hash space. (Decreases the liklihood of hash collisions).\n",
    "\n",
    "\n",
    "------\n",
    "***Hashing Trick***\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ['The cat sat on the mat.','The dog ate my homework.']\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j,word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word))%dimensionality\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings (Dense word vectors)\n",
    "\n",
    "Word embeddings are low dimensional floating point vectors.\n",
    "Basic comparison: Word embeddings are usually of length 256 or 512 for vocablury sizes of 20,000 where the one hot encoded vector would also be 20,000 sized. \n",
    "\n",
    "So, word embeddings capture more information into lower dimensions.\n",
    "\n",
    "There are 2 ways to obtain word embeddings:\n",
    "1. Learn word embeddings jointly with the main task. In this we start with random word vectors and then learn word vectors in the same way we learn the weights of Neural Network. \n",
    "\n",
    "2. Load a pretrained ML model which is responsible for converting text to Word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "***Embedding Layer***\n",
    "\n",
    "--------\n",
    "\n",
    "The main goal of word embeddings is to map semantic relationships between words into the geometrical space. For example if we choose embedding vectors on random, then two words which mean exactly the same would have no proper relation in the geometric space of embeddings.\n",
    "\n",
    "So, when we map all the vectors into space we want the similarity between the vectors to be some form of their reelationshsip in the language. For example the words \"exact\" and \"accurate\" should be very close. The animals belonging to particular category should be closer. So, in short we can see that how this would also be heavily dependent on the task we are trying to perform. \n",
    "\n",
    "When we say the two vectors should be close to each other. We can either consider the L2 distance or the cosine similarity between the two. The cosine similarity is one of the most commonly used measure for similarity of vectors as this is free from relative length of vectors. \n",
    "\n",
    "**Keras Embedding Layer** makes it easier to learn the word embeddings using backpropogation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000,64)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The parameters are:**\n",
    "\n",
    "1. The number of tokens = 1 + maximum word index\n",
    "2. Dimensionality of embeddings\n",
    "\n",
    "Embeddings layer can be considered as a dictionary which maps a sentence with a Dense Vector. \n",
    "\n",
    "\n",
    "**Input:** The embeddings layer takes 2D tensors as input. The tensor is (samples, sequence_length). It can also embed sequence of variable lengths. All sequences in the same tensor should have same lengths. If the sequence lengths are shorter we can pad the vectors with 0's. The longer sequences can be truncated. \n",
    "\n",
    "\n",
    "**Output:**:  The embeddings layer returns a 3D tensor i.e. (samples,sequence_length, embeddings_dimensionality). Such a tensor can be then passed to a RNN, or a 1D CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "\n",
    "***To understand embeddings let's start with the IMDB Dataset***\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "\n",
    "### COnverts into tensors of shape (samples, maxlen)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using a embeddings layer and classifier on IMDB Dataset\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000,8, input_length= maxlen)) ## Returns a 3D tensor of shape (samples, maxlen, 8)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.6759 - acc: 0.6050 - val_loss: 0.6398 - val_acc: 0.6814\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.5657 - acc: 0.7427 - val_loss: 0.5467 - val_acc: 0.7206\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.4752 - acc: 0.7808 - val_loss: 0.5113 - val_acc: 0.7384\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.4263 - acc: 0.8077 - val_loss: 0.5008 - val_acc: 0.7452\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.3930 - acc: 0.8258 - val_loss: 0.4981 - val_acc: 0.7538\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.3668 - acc: 0.8395 - val_loss: 0.5014 - val_acc: 0.7530\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.3435 - acc: 0.8533 - val_loss: 0.5052 - val_acc: 0.7520\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.3223 - acc: 0.8657 - val_loss: 0.5132 - val_acc: 0.7486\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.3022 - acc: 0.8766 - val_loss: 0.5213 - val_acc: 0.7490\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.2839 - acc: 0.8860 - val_loss: 0.5303 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs =10, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have just dealt with a Simple Dense layer which won't capture the relative meanings of words. For that special RNN, or 1D CNN  has to be used. This model we just trained works by checking what words are present and not their order. (Bag of Words model) still this naive basic model gives an accuracy of about 75 percent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "***Using Pretrained Embeddings***\n",
    "\n",
    "-------\n",
    "\n",
    "Suppose we are dealing with a scenario where we have very less data. SO the embeddings layer won't be able to learn task related embeddings. \n",
    "So in such cases we can use the pretrained embeddings which are trained or very large datasets, either entire wikipedia data, or web crawled data for such purposes. These word embeddings are trained to capture the general language structure. For example one of the most famous embeddings commonly used is the word2vec by google. This model successfully captures semantics like gender. \n",
    "\n",
    "One other publicly available embeddings is GloVe(Global vecotrs for word representation) the project by stanford. The word embeddings are created by factorizing the matrix of word co-occurence statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "***Downloading the text data and working from scratch***\n",
    "\n",
    "-----\n",
    "\n",
    "IMDB Dataset Link: https://www.kaggle.com/iarunava/imdb-movie-reviews-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "imdb_dir = '/home/yash/Datasets/imdb-movie-reviews-dataset/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100 ### Cut off reviews after 100 words\n",
    "training_samples = 200 \n",
    "validation_samples = 10000\n",
    "max_words = 10000 ### Consider only top 10000 words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88582"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NUmber of unique words\n",
    "\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shuffling the data\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "\n",
    "x_val = data[training_samples :training_samples + validation_samples]\n",
    "y_val = labels[training_samples :training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "***Downloading Precomputed embeddings***\n",
    "\n",
    "-------------\n",
    "\n",
    "Download Link: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "\n",
    "***Download the following***\n",
    "Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 50d, 100d, 200d, & 300d vectors, 822 MB download): glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = '/home/yash/Datasets/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glove contains 100D embedding vectors for 400000 words or non words tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a embedding matrix to set the embeddings layer weights. The shape of the embeddings layer is ***(max_words, embedding_dim)***. \n",
    "\n",
    "The index 0 isn't supposed to stand for any word or token - it's a placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            \n",
    "            ### Words not found in the embedding index will all be zeros.\n",
    "\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Defining the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we will load the weights matrix for Embedding matrix we just created and freeze that layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x7f14435967b8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.5569 - acc: 0.5400 - val_loss: 0.6912 - val_acc: 0.5373\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5900 - acc: 0.7500 - val_loss: 0.7694 - val_acc: 0.5204\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4713 - acc: 0.7750 - val_loss: 0.7093 - val_acc: 0.5421\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3327 - acc: 0.8950 - val_loss: 0.6779 - val_acc: 0.5752\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2156 - acc: 0.9750 - val_loss: 0.6886 - val_acc: 0.5742\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2408 - acc: 0.9050 - val_loss: 0.7100 - val_acc: 0.5670\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1383 - acc: 0.9900 - val_loss: 1.1271 - val_acc: 0.5063\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1253 - acc: 0.9800 - val_loss: 0.7472 - val_acc: 0.5695\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0512 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.5918\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.4565 - val_acc: 0.5140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10,\n",
    "                   batch_size=32, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(imdb_dir, 'pre_trained_glove_model.h5')\n",
    "model.save_weights(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "\n",
    "\n",
    "plt.title('Losses')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model quickly overfilts given the small number of training samples***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "***Training the same model without using pretrained embeddings***\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6980 - acc: 0.4900 - val_loss: 0.6916 - val_acc: 0.5212\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5193 - acc: 0.9550 - val_loss: 0.6953 - val_acc: 0.5181\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3152 - acc: 0.9850 - val_loss: 0.7049 - val_acc: 0.5202\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1323 - acc: 0.9950 - val_loss: 0.6983 - val_acc: 0.5276\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0601 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.5302\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7117 - val_acc: 0.5326\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.5332\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.5325\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.5329\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.5349\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10,\n",
    "                   batch_size=32, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The accuracy for this model stays in low 50's. Here since we used a very small sample of data using the pretrained weights for training was better. If we increase the training samples this will very quickly stop being the case.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "***Tokenizing and loading the test data***\n",
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = [] \n",
    "texts = []\n",
    "\n",
    "for label_type in ['pos', 'neg']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen = maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 24us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4875309395933152, 0.50676]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
